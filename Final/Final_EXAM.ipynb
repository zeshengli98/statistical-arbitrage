{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248fe069",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pairs Trading Strategy Design & Backtest\n",
    "\n",
    "The definition of Pairs Trading is to take advantage of the mispricing between two or more assets by taking long and short portfolio, betting the related movement will converge back when mispricing situation happening. The principle is buy undervalued and sell overvalued. This is a very charming strategy that we can extend the idea in any market of interest. \n",
    "\n",
    "The first pairs trading bears its roots in equity market, but we can possibly extend the idea into commodities, cryptos, and even options market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104dc909",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37f5127c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import required lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfolio as pf\n",
    "import yfinance as yf\n",
    "from scipy import optimize\n",
    "from scipy.stats import norm\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The numerical techniques are regression computation in matrix form, Engle-Granger procedure, and statistical tests.\n",
    "\n",
    "A) multivariate cointegration (Johansen Procedure)\n",
    "\n",
    "\n",
    "B) robustness checking of cointegration weights, ie, by adaptive estimation of your regression parameters with statistical filters."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Signal Generation and Backtesting\n",
    "- Be inventive beyond equity pairs: consider commodity futures, instruments on interest rates, and aggregated indices. (Initially consider to find the candidate pairs from crude oil)\n",
    "- Arb is relized by using cointegrating coff as allocation w. all project designs should including trading signal generation(OU process fitting) and backtesting.\n",
    "- does P&L behave as expected for cointegration arb trade? Is P&L coming from a few or many trades, what is half-life? Maximum Drawdown and behaviour of volatility/VaR?\n",
    "- Introduce liquidity and algorithmic flow considerations (a model of order flow). Any rules on accumulating the position? What impact bid-ask spread and transaction costs will make?\n",
    "## Step-by-step instructions\n",
    "- multivariate cointegration to identify cases\n",
    "- Part I: pairs trading design\n",
    "    - 1. re-code regression estimation in martrix form - your own OLS implementation which you can re-use. Regression between stationary variables(DF test regression/difference equation) has optional model specification test for (a)identifying optimal lag p with AIC BIC tests and (b) stability check\n",
    "    - 2. Implement Engle-Granger procedure for each pair. Step1 use ADF test for unit root with lag1. Step2, formulate both correction equation and decide which one is more important\n",
    "    - 3. Decide signals: $\\mu_e +- Z\\sigma_{eq}$ and exit on $\\mu_t$\n",
    "    - 4. At first aussme Z=1. Then change Z sightly upwards and downwards - compute P&L for each case of bounds. Alternatively run an optimization that varies Z and maxmize the P&L or other criterion.\n",
    "    - 5. Optionally us VECM in order select the best candidate for pairs trading (or basket trading).\n",
    "    \n",
    "- Part II: Backtesting\n",
    "    - 1. perform systematic backtesting of your trading strategy platform o produce drawdown plots, rolling Sharpe ratio and rolling beta\n",
    "    - 2. keep delivering staionary spread over 3-6 months. Kalman filter will give updated beta. However, you can simply re-estmate cointergration by shifting data 1-2 weeks and report beta and EG.\n",
    "    - 3. use time series CV\n",
    "    \n",
    "    \n",
    "Time Series Project Workshop, Cointegration Lecture and Pairs Trading tutorial are your key resources."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part I: Pairs Trading Design\n",
    "## Data Processing\n",
    "One study by Jacob & Weber conducted several international markets which has empirically proven that the pairs trading works the most in emerging market, either from the high ineffciencies or a large number of available pairs. So I believe some innovative market has more opportunities than equity market.\n",
    "\n",
    "In this case, I want to study model-driven statistical arbitrage strategies in U.S. equities, commodities and crypto market. The crpyto is the youngest and has less research than other assets, which becomes very attractive for pairs trading strategy design. From those three different perspectives, we can identify multiple strategy implementations and more profitable opportunities. So, in the first step, we sort out a list of available symbols and prepare them for filtering."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## In this case, I want to implement pairs trading from two perspectives - equity and commodity market.\n",
    "## First I listed some potentially profitable tickers to be tested from different market.\n",
    "start = '2005-01-01'\n",
    "end = '2022-07-30'\n",
    "tickers_commodity = {'Gold':'GC=F',\n",
    "                     'Sliver':'SI=F',\n",
    "                     'Crude Oil':'CL=F',\n",
    "                     'Natural Gas':'NG=F',\n",
    "                     'Gasoline':'RB=F',\n",
    "                     'E-Mini S&P 500':'ES=F'}\n",
    "\n",
    "tickers_crypto = ['BTC-USD','ETH-USD','ADA-USD','SOL-USD','BNB-USD','DOGE-USD','LTC-USD']\n",
    "\n",
    "tickers_stock = ['']\n",
    "price_commodity = yf.download(list(tickers_commodity.values()), start, end)['Adj Close'].dropna()\n",
    "price_commodity.rename({v:k for k,v in tickers_commodity.items()},axis=1,inplace=True)\n",
    "\n",
    "price_crypto = yf.download(tickers_crypto, '2017-12-01', end)['Adj Close'].dropna()['2021-07':]\n",
    "price_crypto.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "price_commodity.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cointegration Apporach\n",
    "Cointegration: I(d) series, which means integrated series of order d\n",
    "I(1) series: Price\n",
    "I(0) series: Returns\n",
    "The prices of cointegrated assets fluctuate around a certain average level. So cointegration allows us to construct a 2-asset portfolio with stationary series to be traded. Then we are able to construct a mean-reversion strategy.\n",
    "\n",
    "### Find $\\beta_{Coint}$\n",
    "- Engle-Grange test\n",
    "    - Linear regression on the candidate pairs price and calculate its residual\n",
    "    - Test the stationary of the residual\n",
    "- Johansen test\n",
    "    - VECM\n",
    "    \n",
    "    \n",
    "We have two apporaches to find cointegration beta parameter. \n",
    "##### Engle-Grange test\n",
    "The first idea of Engle Granger test is performing a linear regression between two underlying assets and test its residual and see if the series is stationary by applying Augmented Dick-Fuller test. So if the residual is a stationary series, we can say the two prices are cointegrated. The $\\beta_{Coint}$ is obtained as the asset weight to be traded.\n",
    "\n",
    "In the stationarity test, we test for a unit root, which is based on the following hypothesis test:\n",
    "$$H_0: \\phi =1 \\rightarrow y_t \\sim I(0) | (unit root)$$\n",
    "$$H_1:\\mid\\phi\\mid <1 \\rightarrow y_t \\sim I(0) | (stationary)$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pair Candidates Selection\n",
    "Before we do cointegration, we have 2 baskets of asset - commodity and crypto. We will only look for cointegrated pairs inside the basket because ADF test is not good at identifying spurious relationships.\n",
    "\n",
    "A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pairs_selection(prices):\n",
    "    '''\n",
    "    :param prices: dataframe-like, all asset prices to be checked to find candidate pairs\n",
    "    '''\n",
    "    res = pd.DataFrame(columns = ['p-value','aic'])\n",
    "    n = prices.shape[1]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            pairs = prices.iloc[:,[i,j]]\n",
    "#             print(pairs)\n",
    "            pairs_name = f\"({pairs.columns[0]}, {pairs.columns[1]})\"\n",
    "            y = pairs.iloc[:,0]\n",
    "            x = pairs.iloc[:,1]\n",
    "            beta, resid, summary = OLS(y, x)\n",
    "            \n",
    "            summary, p, aic = ADF_test(resid, pairs_name, verbose=False)\n",
    "            res.loc[pairs_name] = [p, aic]\n",
    "    res.sort_values(by=['p-value'],inplace=True)\n",
    "    return res\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering of Commodity Basket\n",
    "By calculating the ADF p-values for all pairs, we find that crude oil and gasoline have the most significant cointegration relationship, which is highly reasonable because the properties of these two commodities are very close, with crude oil being the raw material for gasoline.\n",
    "\n",
    "So in the commodity basekt, we will further study this candidate pair."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairs_selection(price_commodity).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_commodity = price_commodity.loc[:,'Crude Oil']\n",
    "x_commodity = price_commodity.loc[:,'Gasoline']\n",
    "\n",
    "beta_commodity, resid_commodity, summary_commodity = OLS(y_commodity, x_commodity)\n",
    "# resid.plot(figsize=(10,8))\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.plot(resid_commodity)\n",
    "ax.set_title('Res(Crude Oil, Gasoline)')\n",
    "ax.set_xlabel('Date')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering of Crypto Basket\n",
    "The cryptocurrency market is very volatile and we can't ensure that the pairs have all time cointegration, so we are looking forward a year to find the relationship over that time.\n",
    "\n",
    "Fortunately, we found that the BNB-ETH pair was a possible integrated pair in the previous year, so we can assume that this relationship will be maintained for a short time in the following."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairs_selection(price_crypto).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_crypto = price_crypto.loc[:,'BNB-USD']\n",
    "x_crypto = price_crypto.loc[:,'ETH-USD']\n",
    "\n",
    "beta_crypto, resid_crypto, summary_crypto = OLS(y_crypto, x_crypto)\n",
    "# resid.plot(figsize=(10,8))\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.plot(resid_crypto)\n",
    "ax.set_title('Res(BNB, ETH)')\n",
    "ax.set_xlabel('Date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ENGLE-GRANGER STEP 1. Cointegrated Residual"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def OLS(y, x):\n",
    "    '''\n",
    "    parameters:\n",
    "    :param y: independent variable, dataframe or array-like\n",
    "    :param x: dependent variables, dataframe or array-like\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "\n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "\n",
    "    residuals = model.resid\n",
    "    residuals = pd.DataFrame({'resid':residuals},index = x.index)\n",
    "    ## OLS params\n",
    "    c, beta = model.params\n",
    "\n",
    "    ## OLS params sd\n",
    "    c_sd, beta_sd = model.bse\n",
    "\n",
    "    # OLS t-statistics\n",
    "    c_t, beta_t = model.tvalues\n",
    "    \n",
    "    \n",
    "    summary = pd.DataFrame({\"Params\":model.params,\n",
    "                       \"Error\":model.bse,\n",
    "                       'T-stats':model.tvalues,\n",
    "                       'P-values': model.pvalues})\n",
    "    \n",
    "    return beta, residuals, np.around(summary,2)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ADF test\n",
    "**ADF test equation**\n",
    "use ADF test for unit root with lag1:\n",
    "$$\\Delta e_t = \\varphi e_{t-1} + \\varphi_{aug1}\\Delta e_{t-1} + const + \\varphi_tt+\\epsilon_t$$\n",
    "- Improvement 1. Test equation above includes time dependence  $\\varphi_tt$ , referred to as 'trend'.\n",
    "I don't include trend in the ADF tests and cointegrating residual -- it will make me think cointegration is present when it is very weak. In fact, without $\\varphi_tt$ term, we might not even get stationarity result."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ADF_test(resid, name, verbose=True):\n",
    "    # H_0 in adfuller is unit root exists (non-stationary)\n",
    "    # We must observe significant p-value to convince ourselves that the series is stationary\n",
    "    '''\n",
    "    :param resid: dataframe-like, the residual from OLS or any other series to be tested\n",
    "    '''\n",
    "    index = resid.index\n",
    "    resid = np.array(resid).flatten()\n",
    "    series = pd.DataFrame({'e_t':resid},index = index)\n",
    "    series['e_t-1'] = series['e_t'].shift(1)\n",
    "    series['Œîe_t'] = series['e_t'].diff()\n",
    "    series['Œîe_t-1'] = series['e_t'].diff().shift(1)\n",
    "    \n",
    "    series = series.dropna()\n",
    "    x = series[['e_t-1','Œîe_t-1']]\n",
    "    y = series['Œîe_t']\n",
    "    \n",
    "    model = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "\n",
    "    summary = pd.DataFrame({f\"Estimate ŒîRes({name})\":model.params,\n",
    "                           f\"SD of Estimate ŒîRes({name})\":model.bse,\n",
    "                           f\"t-Statistic ŒîRes({name})\":model.tvalues,\n",
    "                           f\"P-value ŒîRes({name})\":model.pvalues})\n",
    "    summary = np.around(summary,6)\n",
    "#     display(summary)\n",
    "\n",
    "    adf = adfuller(series['e_t'],regression='c')\n",
    "    aic = adf[-1]\n",
    "\n",
    "    pvalue = round(adf[1],6)\n",
    "    if verbose==True:\n",
    "        print(\"---------ADF result--------:\")\n",
    "        if pvalue < 0.05:\n",
    "            print('p-value = ' + str(pvalue) + ' The series ' + name +' is likely stationary.')\n",
    "        else:\n",
    "            print('p-value = ' + str(pvalue) + ' The series ' + name +' is likely non-stationary.')\n",
    "    \n",
    "    return summary, pvalue, aic\n",
    "\n",
    "summary, p, aic = ADF_test(resid_commodity, 'Crude Oil, Gasoline')\n",
    "display(summary)\n",
    "summary, p, aic = ADF_test(resid_crypto, 'BNB, ETH') \n",
    "display(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both pairs passed the ADF test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### ENGLE-GRANGER STEP 2. Error correction equations\n",
    "In general form, \n",
    "$$\\Delta P_t^A = \\varphi \\Delta P_t^B - (1-\\alpha) \\tilde e^A_{t-1} + \\epsilon_t$$\n",
    "\n",
    "In the other way around:\n",
    "$$\\Delta P_t^B = \\varphi \\Delta P_t^A - (1-\\alpha) \\tilde e^A_{t-1} + \\epsilon_t$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def EG_err_corr1(S1, S2, e, name):\n",
    "    '''\n",
    "    :param S1: dataframe-like, the price of asset A\n",
    "    :param S2: dataframe-like, the price of asset B\n",
    "    :param e: dataframe-like, the residual between A and B\n",
    "    '''\n",
    "    dS1 = np.array(S1.diff()).flatten()\n",
    "    dS2 = np.array(S2.diff()).flatten()\n",
    "    \n",
    "    e = np.array(e.shift(1)).flatten()\n",
    "    df_to_fit = pd.DataFrame({'ŒîPA_t':dS1,\n",
    "                             'ŒîPB_t':dS2,\n",
    "                             'e_t-1':e}).dropna()\n",
    "    \n",
    "    x = df_to_fit[['ŒîPB_t','e_t-1']]\n",
    "    y = df_to_fit['ŒîPA_t']\n",
    "    \n",
    "    model = sm.OLS(y, x).fit()\n",
    "\n",
    "    summary = pd.DataFrame({f\"Estimate Œî{name}\":model.params,\n",
    "                           f\"SD of Estimate Œî{name}\":model.bse,\n",
    "                           f\"t-Statistic Œî{name}\":model.tvalues,\n",
    "                           f\"P-value Œî{name}\":model.pvalues})\n",
    "    summary = np.round(summary,6)\n",
    "    return summary, model.pvalues\n",
    "summary, p = EG_err_corr1(y_commodity, x_commodity, resid_commodity, 'Gasoline')\n",
    "display(summary)\n",
    "summary, p = EG_err_corr1(y_crypto, x_crypto, resid_crypto, 'ETH')\n",
    "display(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now perform **the 2nd step of EG to estimate the Equilibrium Correction Model**, Here we check the significance of -(1-ùõº) term, which ensure the correction the long run equilibrium. In error correction equation the p-value is significantly showing 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def EG_err_corr2(S1, S2, e, name):\n",
    "    '''\n",
    "    :param S1: dataframe-like, the price of asset A\n",
    "    :param S2: dataframe-like, the price of asset B\n",
    "    :param e: dataframe-like, the residual between A and B\n",
    "    '''\n",
    "    dS1 = np.array(S1.diff()).flatten()\n",
    "    dS2 = np.array(S2.diff()).flatten()\n",
    "    \n",
    "    e = np.array(e.shift(1)).flatten()\n",
    "    df_to_fit = pd.DataFrame({'ŒîPA_t':dS1,\n",
    "                             'ŒîPB_t':dS2,\n",
    "                             'e_t-1':e}).dropna()\n",
    "    \n",
    "    x = df_to_fit[['ŒîPA_t','e_t-1']]\n",
    "    y = df_to_fit['ŒîPB_t']\n",
    "    \n",
    "    model = sm.OLS(y, x).fit()\n",
    "\n",
    "    summary = pd.DataFrame({f\"Estimate Œî{name}\":model.params,\n",
    "                           f\"SD of Estimate Œî{name}\":model.bse,\n",
    "                           f\"t-Statistic Œî{name}\":model.tvalues,\n",
    "                           f\"P-value Œî{name}\":model.pvalues})\n",
    "    summary = np.round(summary,6)\n",
    "    \n",
    "    return summary, model.pvalues\n",
    "summary, p = EG_err_corr2(y_commodity, x_commodity, resid_commodity, 'Crude Oil')\n",
    "display(summary)\n",
    "summary, p = EG_err_corr2(y_crypto, x_crypto, resid_crypto, 'BNB')\n",
    "display(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we estimate the EG correction equation \"other way around\", both shows the significance.\n",
    "From the absolute value of t-stas, the first way is the more important model. So the pair is considered to be cointegrated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Ornstein-Uhlenbeck process\n",
    "\n",
    "In order to find the optimal $\\beta_{Coint}$ to build the best mean reversion portfolio, we can fit the OU process.\n",
    " \n",
    "The Ornstein-Uhlenbeck process is described by the following SDE:\n",
    "\n",
    "$$ dX_t = \\kappa (\\theta - X_t) dt + \\sigma dW_t $$\n",
    "\n",
    "The parameters are:\n",
    "- $\\theta \\in \\mathbb{R}$: The long-term average, around which all trajectories of $X_t$ oscillate, is the mean level.\n",
    "\n",
    "- $\\kappa > 0$: the speed of mean reversion, represents the velocity at which such trajectories will regroup around mean level\n",
    "\n",
    "- $\\sigma > 0$: instantaneous volatility, measures the amplitude of randomness entering the system.\n",
    "\n",
    "\n",
    "At this point we can solve the SDE:\n",
    "\n",
    "$$ X_t = \\theta + (X_0 - \\theta)e^{-\\kappa t} + \\int_0^t \\sigma\\, e^{\\kappa (s-t)} dW_s .$$\n",
    "\n",
    "\n",
    "### Moments:\n",
    "\n",
    "The **mean** of $X_t$ is:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "\\mathbb{E}[X_t] &= \\mathbb{E}\\biggl[ \\theta + (X_0 - \\theta)e^{-\\kappa t} + \\int_0^t \\sigma\\, e^{\\kappa (s-t)} dW_s \\biggr] \\\\\n",
    "                &= \\theta + (X_0 - \\theta)e^{-\\kappa t}    \n",
    "\\end{aligned}$$\n",
    "\n",
    "The **covariance** is:\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "\\text{Cov}[X_s, X_t] &= \\frac{\\sigma^2}{2\\kappa} \\biggl( e^{-\\kappa |t-s|} - e^{-\\kappa (s+t)}\\, \\biggr),  \n",
    "\\end{aligned}$$\n",
    "\n",
    "The **variance** is: \n",
    "\n",
    "$$ \\text{Var}[X_t] = \\text{Cov}[X_t, X_t] = \\frac{\\sigma^2}{2\\kappa} \\biggl( 1- e^{-2 \\kappa t} \\biggr).$$\n",
    "\n",
    "So, we can obtain the **mean**: $\\theta$ and the **variance**: $\\frac{\\sigma^2}{2\\kappa}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We can discretize the SDE using the Euler-Maruyama numerical method:\n",
    "\n",
    "Let us consider the solution of the OU SDE obtained above. We can compute $X_{n+1}$ and consider the initial value at time $n$.\n",
    "\n",
    "$$ X_{n+1} = \\theta + (X_n - \\theta)e^{-\\kappa \\Delta t} + \\sqrt{\\frac{\\sigma^2}{2\\kappa} \\bigl( 1- e^{-2 \\kappa \\Delta t} \\bigr)} \\; \\epsilon_n $$ \n",
    "\n",
    "with $\\epsilon_n \\sim \\mathcal{N}(0,1)$.\n",
    "\n",
    "\n",
    "\n",
    "## Estimation of parameters\n",
    "\n",
    "We can compute $X_{t+\\Delta t}$ and consider the initial value at time $t$.\n",
    "\n",
    "$$ \\begin{aligned}\n",
    "X_{t+\\Delta t} &= \\theta + (X_t - \\theta)e^{-\\kappa \\Delta t} + \\int_t^{t+\\Delta t} \\sigma\\, e^{\\kappa (s-t)} dW_s \\\\\n",
    "               &= \\theta \\bigl( 1-e^{-\\kappa \\Delta t} \\bigr) + e^{-\\kappa \\Delta t} X_t + \\int_t^{t+\\Delta t} \\sigma\\, e^{\\kappa (s-t)} dW_s \\\\\n",
    "               &= \\alpha + \\beta X_t + \\epsilon_t\n",
    "\\end{aligned} $$\n",
    "\n",
    "where $\\alpha = \\theta \\bigl( 1-e^{-\\kappa \\Delta t} \\bigr)$, $\\beta = e^{-\\kappa \\Delta t}$ and with $\\epsilon_t \\sim \\mathcal{N}\\biggl( 0, \\frac{\\sigma^2}{2\\kappa} \\bigl( 1- e^{-2 \\kappa \\Delta t} \\bigr)\\biggr)$.\n",
    "\n",
    "So, this confirms the saying from \"The Ornstein‚ÄìUhlenbeck process can also be considered as the continuous-time analogue of the discrete-time AR(1) process.\" and we are able to guarantee the AR(1) process to estimate the params on the spread. \n",
    "\n",
    "let us use the usual OLS method to estimate $\\alpha$, $\\beta$ and $\\sigma$.\n",
    "Then, we can obtain the parameters from the formulas:\n",
    "\n",
    "$$ \\kappa = - \\frac{\\log \\beta}{\\Delta t}, \\quad \\theta = \\frac{\\alpha}{1-\\beta}, \\quad \n",
    "\\sigma = \\text{Std}[\\epsilon_t] \\sqrt{ \\frac{2\\kappa}{1-\\beta^2} }$$\n",
    "\n",
    "we can obtain almost consistent parameters to those params obtained by MLE.\n",
    "\n",
    "Halflife:\n",
    "$$Halflife(days) = \\frac{ln(2)}{\\theta*dt}$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class OU_process:\n",
    "    def __init__(self, freq = 'D'):\n",
    "        if freq =='D':\n",
    "            self.dt = 1/252\n",
    "        elif freq=='H':\n",
    "            self.dt = 1/252/60\n",
    "        elif freq==\"M\":\n",
    "            self.dt = 1/252/60/60\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self,resid, verbose = True):\n",
    "        X = np.array(resid[:-1]).flatten()\n",
    "        Y = np.array(resid[1:]).flatten()\n",
    "\n",
    "        model = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "        alpha, beta = model.params\n",
    "        kappa = - np.log(beta)/self.dt\n",
    "        theta = alpha/(1-beta)\n",
    "        res = Y - beta * X - alpha                   # residuals\n",
    "        std_resid = np.std(res, ddof=2)\n",
    "        sigma = std_resid * np.sqrt(2*kappa/(1-beta**2))\n",
    "        sigma_eq = std_resid*np.sqrt(1/(1-beta**2))\n",
    "        halflife = np.log(2)/kappa/dt\n",
    "        if verbose:\n",
    "            print(\"OU process params:\")\n",
    "            print(f\"theta = {theta:.4f}\")\n",
    "            print(f\"kappa = {kappa:.4f}\")\n",
    "            print(f\"sigma = {sigma:.4f}\")\n",
    "            print(f\"sigma_eq = {sigma_eq:.4f}\")\n",
    "            print(f\"halflife = {halflife:.4f}\")\n",
    "        self.params = {'theta':theta,'kappa':kappa, 'sigma':sigma,'sigma_eq':sigma_eq,'halflife':halflife}\n",
    "        return self\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Commodity basket OU process fitting\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def OU_process_pairs_selection(prices, kappa_thres = 5):\n",
    "    res = pd.DataFrame(columns = ['theta','kappa', 'sigma','sigma_eq','halflife'])\n",
    "    resid_df = pd.DataFrame(index = prices.index)\n",
    "    n = prices.shape[1]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            pairs = prices.iloc[:,[i,j]]\n",
    "            pairs_name = f\"({pairs.columns[0]}, {pairs.columns[1]})\"\n",
    "            y = pairs.iloc[:,0]\n",
    "            x = pairs.iloc[:,1]\n",
    "            beta, resid, summary = OLS(y, x)\n",
    "            \n",
    "            params = OU_process().fit(resid,verbose=False).params\n",
    "            if params['kappa']>kappa_thres:\n",
    "                res.loc[pairs_name] = list(params.values())\n",
    "                resid_df[pairs_name] = resid\n",
    "    res.sort_values(by=['kappa'],ascending=False,inplace=True)\n",
    "    return res, resid_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res, resid_df = OU_process_pairs_selection(price_commodity)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res, resid_df = OU_process_pairs_selection(price_crypto, kappa_thres=8)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "OU process pairs selection\n",
    "\n",
    "Ëß£Èáä‰∏Ä‰∏ãÁªßÁª≠ÈÄâÊã©ÈÇ£‰∏§‰∏™pairÊòØÂêàÁêÜÁöÑ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Signal Generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Source:\n",
    "[1] https://www.sciencedirect.com/science/article/abs/pii/S1386418114000809\n",
    "\n",
    "[2] https://github.com/cantaro86/Financial-Models-Numerical-Methods/blob/master/6.1%20Ornstein-Uhlenbeck%20process%20and%20applications.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "ff42559b",
   "metadata": {},
   "source": [
    "# Signal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b175e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210520e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6b2dc6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Source:\n",
    "[1] https://www.sciencedirect.com/science/article/abs/pii/S1386418114000809\n",
    "\n",
    "[2] https://github.com/cantaro86/Financial-Models-Numerical-Methods/blob/master/6.1%20Ornstein-Uhlenbeck%20process%20and%20applications.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "0e54726d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E-Mini S&amp;P 500</th>\n",
       "      <th>Natural Gas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>1206.25</td>\n",
       "      <td>5.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>1191.00</td>\n",
       "      <td>5.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>1183.25</td>\n",
       "      <td>5.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>1188.25</td>\n",
       "      <td>6.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>1186.25</td>\n",
       "      <td>6.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-25</th>\n",
       "      <td>3970.00</td>\n",
       "      <td>8.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-26</th>\n",
       "      <td>3923.25</td>\n",
       "      <td>8.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>4024.50</td>\n",
       "      <td>8.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>4073.50</td>\n",
       "      <td>8.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>4133.50</td>\n",
       "      <td>8.229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4414 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            E-Mini S&P 500  Natural Gas\n",
       "Date                                   \n",
       "2005-01-03         1206.25        5.790\n",
       "2005-01-04         1191.00        5.902\n",
       "2005-01-05         1183.25        5.833\n",
       "2005-01-06         1188.25        6.049\n",
       "2005-01-07         1186.25        6.001\n",
       "...                    ...          ...\n",
       "2022-07-25         3970.00        8.727\n",
       "2022-07-26         3923.25        8.993\n",
       "2022-07-27         4024.50        8.687\n",
       "2022-07-28         4073.50        8.134\n",
       "2022-07-29         4133.50        8.229\n",
       "\n",
       "[4414 rows x 2 columns]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_commodity.iloc[:,[1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "9b868cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df74467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}